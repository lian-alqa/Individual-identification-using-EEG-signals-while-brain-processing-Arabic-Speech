# -*- coding: utf-8 -*-
"""FinalModelSIC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r6cvxhgSRB7TRa8sddnIPQjJsTqBmHrl

# EEG Subject Identification using CNN

This project uses a Convolutional Neural Network (CNN) to identify individuals based on EEG signals recorded during Arabic speech processing.

**Model Details:**

- **Goal:** Classify EEG signals among 12 different subjects.  
- **Classification Type:** Multi-Class.  
- **Output Layer:** Softmax with 12 nodes.  
- **Loss Function:** Sparse Categorical Crossentropy.  
- **Features:**  
  - Temporal and spatial feature extraction using Conv2D and DepthwiseConv2D.  
  - Refining Blocks (Residual Dense) to enhance learning.  
  - GlobalAveragePooling to reduce dimensionality before the output layer.  
- **Input Shape:** `(samples, 8 channels, 1200 time points, 1)`  
- **Achieved Accuracy:** ~86% on the test set.

# Imports Cell
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics import classification_report, accuracy_score

"""# Data Loading & Constants"""

import pandas as pd
df = pd.read_csv("/content/sample_data/RIGHT_Real.csv")

display(df.head())

print(df.columns.tolist())

df.info()

NUM_CHANNELS = 8
TIME_POINTS = 1200
num_classes = 12

EPOCHS = 50
BATCH_SIZE = 32
INITIAL_LR = 1e-3

"""# CNN (EEG CNN Model)

--------
"""

def build_eeg_model(input_shape, num_classes,
                    BASE_FILTERS=32,
                    K_TEMPORAL=25,
                    DROPOUT=0.6,
                    WEIGHT_DECAY=1e-4,
                    REFINING_BLOCKS=1):

    inp = layers.Input(shape=input_shape)     # (NUM_CHANNELS, TIME_POINTS, 1) e.g., (8, 1200, 1)
    x   = inp

    # 1) Temporal Conv على الزمن (Convolve along time axis)
    # Input: (None, Channels, TimePoints, 1)
    # Kernel should be (1, K_TEMPORAL) to convolve along TimePoints (axis=2)
    x = layers.Conv2D(
        filters=BASE_FILTERS,
        kernel_size=(1, K_TEMPORAL), # Corrected: convolve along time axis
        padding='same',
        kernel_regularizer=regularizers.l2(WEIGHT_DECAY),
        use_bias=False,
    )(x)
    # Shape after this: (None, NUM_CHANNELS, TIME_POINTS, BASE_FILTERS) e.g., (None, 8, 1200, 16)
    x = layers.BatchNormalization()(x)
    x = layers.ELU()(x)

    # 2) Spatial Depthwise Conv على القنوات (Convolve along channel axis)
    # Input: (None, Channels, TimePoints, BASE_FILTERS)
    # Kernel should be (NUM_CHANNELS, 1) to convolve along Channels (axis=1) and collapse them
    x = layers.DepthwiseConv2D(
        kernel_size=(NUM_CHANNELS, 1), # Corrected: convolve along channel axis
        depth_multiplier=1,
        depthwise_regularizer=regularizers.l2(WEIGHT_DECAY),
        use_bias=False,
    )(x)
    # Shape after this: (None, 1, TIME_POINTS, BASE_FILTERS * depth_multiplier) e.g., (None, 1, 1200, 16)
    x = layers.BatchNormalization()(x)
    x = layers.ELU()(x)

    # 3) Pooling + Dropout
    # Input: (None, 1, TimePoints, Features)
    # Pool along TimePoints dimension (axis=2)
    x = layers.AveragePooling2D(pool_size=(1, 2))(x) # Corrected: pool along time axis
    # Shape after this: (None, 1, TIME_POINTS / 2, BASE_FILTERS * depth_multiplier) e.g., (None, 1, 600, 16)
    x = layers.Dropout(DROPOUT)(x)

    # 4) Squeeze (حذف بعد العرض = 1)
    # Now, axis=1 has size 1. This is the dimension to squeeze.
    # Input: (None, 1, 600, 16) (assuming BASE_FILTERS=16, depth_multiplier=1)
    # Squeezing axis=1 results in (None, 600, 16)

    # Calculate the output shape for the Lambda layer (excluding batch dimension)
    output_dim1 = TIME_POINTS // 2
    output_dim2 = BASE_FILTERS * 1 # Assuming depth_multiplier=1
    lambda_output_shape = (output_dim1, output_dim2)

    x = layers.Lambda(lambda y: tf.squeeze(y, axis=1), output_shape=lambda_output_shape)(x) # Corrected: squeeze axis=1 and added output_shape
    # Shape after this: (None, 600, 16) - This is (T', F) for GlobalAveragePooling1D

    # 5) Refining blocks (اختياري)
    # Input: (None, T', F)
    new_shape_features = output_dim2 # F from (T', F)
    for _ in range(REFINING_BLOCKS):
        skip = x
        x = layers.Dense(new_shape_features // 2, activation='relu')(x)
        x = layers.Dropout(DROPOUT)(x)
        x = layers.Dense(new_shape_features, activation='relu')(x)
        x = layers.Add()([x, skip])

    # 6) Global pooling + classifier
    x   = layers.GlobalAveragePooling1D()(x) # Input (None, T', F) -> Output (None, F)
    out = layers.Dense(num_classes, activation='softmax')(x)

    model = models.Model(inp, out, name="EEG_SubjectID_CNN_Optimized")
    return model

"""# (Data Preprocessing)

(Input & Target Variables)
"""

# ----- DROP subject0 COMPLETELY -----
df = df[df['subject'] != 'subject0'].reset_index(drop=True)
print(df['subject'].value_counts())   # just to check


X_df = df.filter(regex=r'^v\d+$').iloc[:, : (NUM_CHANNELS * TIME_POINTS)]
Y_df = df['subject']

"""(Label Encoding)"""

# Input & Target Variables
Y_df = df['subject'].astype(str)

# Label Encoding
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
Y_encoded = le.fit_transform(Y_df)

num_classes = len(le.classes_)
print("Subjects (kept):", le.classes_)
print("num_classes:", num_classes)

"""(Train/Validation/Test Split )"""

X_temp, X_test, Y_temp, Y_test = train_test_split(
    X_df.values, Y_encoded,
    test_size=0.2,
    random_state=42,
    stratify=Y_encoded
)

X_train, X_val, Y_train, Y_val = train_test_split(
    X_temp, Y_temp,
    test_size=0.25,
    random_state=42,
    stratify=Y_temp
)

print("X_train shape:", X_train.shape)
print("X_val shape:",   X_val.shape)
print("X_test shape:",  X_test.shape)

"""(Scaling)

CNN (Reshape for CNN)
"""

from sklearn.preprocessing import StandardScaler

# ----- Scaling على شكل (samples, features) -----
scaler = StandardScaler()

X_train_flat = X_train.reshape(X_train.shape[0], -1)
X_val_flat   = X_val.reshape(X_val.shape[0], -1)
X_test_flat  = X_test.reshape(X_test.shape[0], -1)

X_train_scaled = scaler.fit_transform(X_train_flat)
X_val_scaled   = scaler.transform(X_val_flat)
X_test_scaled  = scaler.transform(X_test_flat)

# ----- Reshape إلى (trials, 8, 1200, 1) -----
input_shape = (NUM_CHANNELS, TIME_POINTS, 1)

X_train_cnn = X_train_scaled.reshape(-1, NUM_CHANNELS, TIME_POINTS, 1)
X_val_cnn   = X_val_scaled.reshape(-1, NUM_CHANNELS, TIME_POINTS, 1)
X_test_cnn  = X_test_scaled.reshape(-1, NUM_CHANNELS, TIME_POINTS, 1)

print(f"Data ready. X_train_cnn shape: {X_train_cnn.shape}")
print(f"             X_val_cnn   shape: {X_val_cnn.shape}")
print(f"             X_test_cnn  shape: {X_test_cnn.shape}")

"""# (Class Weights)"""

class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(Y_train),
    y=Y_train,
)
class_weights_dict = dict(enumerate(class_weights))
print("Calculated Class Weights:", class_weights_dict)

"""# (Build & Compile Model)"""

from tensorflow.keras.optimizers import Adam

model = build_eeg_model(
    input_shape,
    num_classes,
    BASE_FILTERS=16,   # جرب 16 أو 32
    K_TEMPORAL=25,
    DROPOUT=0.5,
    WEIGHT_DECAY=1e-4,
    REFINING_BLOCKS=1  # كتلة تحسين واحدة
)

optimizer = Adam(learning_rate=1e-3)

model.compile(
    optimizer=optimizer,
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy'],
)

model.summary()

"""# Callbacks

# (Model Training )
"""

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

callbacks = [
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=4,
        min_lr=1e-5,
        verbose=1,
    ),

]

history = model.fit(
    X_train_cnn, Y_train,
    epochs=40,
    batch_size=16,
    validation_data=(X_val_cnn, Y_val),
    class_weight=class_weights_dict,
    verbose=1,
    callbacks=callbacks,
)

"""##Evalutaion Metrics"""

import matplotlib.pyplot as plt

# الرسم البياني للدقة (Accuracy)
plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', color='#1f77b4', linewidth=2, marker='s')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='#ff7f0e', linewidth=2, linestyle='--', marker='o')
plt.title('Model Accuracy vs Epochs', fontsize=16)
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(axis='y', linestyle='--')

# الرسم البياني للخسارة (Loss)
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', color='#1f77b4', linewidth=2, marker='s')
plt.plot(history.history['val_loss'], label='Validation Loss', color='#ff7f0e', linewidth=2, linestyle='--', marker='o')
plt.title('Model Loss vs Epochs', fontsize=16)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(axis='y', linestyle='--')

plt.tight_layout()
plt.show()

"""Test & Evaluate Model

##Test the model
"""

# ===========================================
#               TEST & EVALUATE
# ===========================================
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

# ----- 1) Evaluate on Test Set -----
test_loss, test_accuracy = model.evaluate(X_test_cnn, Y_test, verbose=0)

print("\n" + "="*60)
print(f"Final Test Accuracy: {test_accuracy*100:.2f}%")
print(f"Final Test Loss    : {test_loss:.4f}")
print("="*60)

# ----- 2) Predictions -----
Y_pred_raw = model.predict(X_test_cnn, verbose=0)
Y_pred = np.argmax(Y_pred_raw, axis=1)

# ----- 3) Classification Report -----
print("\n[TEST] Classification Report:")
print(classification_report(Y_test, Y_pred, target_names=le.classes_))

# ----- 4) Confusion Matrix -----
cm = confusion_matrix(Y_test, Y_pred)
print("\n[TEST] Confusion Matrix:\n", cm)

# ----- 5) Plot Confusion Matrix -----
plt.figure(figsize=(6,5))
plt.imshow(cm, cmap='Blues')
plt.title("Test Confusion Matrix", fontsize=16)
plt.xlabel("Predicted", fontsize=12)
plt.ylabel("True", fontsize=12)
plt.colorbar()

# تضع أسماء الـ subjects تحت/يمين
plt.xticks(ticks=np.arange(num_classes), labels=le.classes_, rotation=45, ha='right')
plt.yticks(ticks=np.arange(num_classes), labels=le.classes_)

# كتابة الأرقام داخل المربعات
for i in range(num_classes):
    for j in range(num_classes):
        plt.text(j, i, cm[i, j], ha="center", va="center", color="black", fontsize=12)

plt.tight_layout()
plt.show()

# =====================================================
#   Select 5 samples from 5 different subjects
# =====================================================
selected_indices = []
seen_classes = set()

for idx, y in enumerate(Y_test):
    if y not in seen_classes:
        selected_indices.append(idx)
        seen_classes.add(y)
    if len(selected_indices) == 5:
        break

print("\n[TEST] Example predictions (5 samples from different subjects):\n")
for k, idx in enumerate(selected_indices):
    true_class_id = Y_test[idx]
    pred_class_id = Y_pred[idx]

    true_label = le.classes_[true_class_id]
    pred_label = le.classes_[pred_class_id]
    confidence = Y_pred_raw[idx, pred_class_id]

    print(f"Example {k+1}:")
    print(f"  Test index    : {idx}")
    print(f"  True subject  : {true_label} (class {true_class_id})")
    print(f"  Predicted subj: {pred_label} (class {pred_class_id})")
    print(f"  Confidence    : {confidence:.3f}")
    print("-" * 40)


# =====================================================
#        Beautiful Percent Heatmap for the 5 Samples
# =====================================================
import matplotlib.pyplot as plt
import numpy as np

prob_subset = (Y_pred_raw[selected_indices] * 100)   # convert to %
rows, cols = prob_subset.shape

plt.figure(figsize=(12, 5))
plt.imshow(prob_subset, aspect='auto', cmap='viridis')

plt.colorbar(label='Probability (%)')
plt.title("Test Probability Vectors (5 Samples • Percent Annotated)", fontsize=14)

# x-axis class labels
plt.xticks(
    ticks=np.arange(num_classes),
    labels=le.classes_,
    rotation=45, ha='right', fontsize=10
)

# y-axis labels (sample index + True/Predicted)
yt_labels = [
    f"idx {idx}\nT:{le.classes_[Y_test[idx]]}  P:{le.classes_[Y_pred[idx]]}"
    for idx in selected_indices
]
plt.yticks(ticks=np.arange(len(selected_indices)), labels=yt_labels, fontsize=10)

# ----- Add percentage values inside each box -----
for i in range(rows):
    for j in range(cols):
        value = prob_subset[i, j]

        # choose text color (white if background is bright)
        text_color = "white" if value > 50 else "black"

        plt.text(
            j, i,
            f"{value:.0f}%",
            ha='center', va='center',
            fontsize=9, color=text_color, fontweight='bold'
        )

plt.xlabel("Class", fontsize=12)
plt.ylabel("Test Sample", fontsize=12)
plt.tight_layout()
plt.show()